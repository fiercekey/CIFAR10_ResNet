{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-02T16:53:57.330830Z","iopub.execute_input":"2024-07-02T16:53:57.331167Z","iopub.status.idle":"2024-07-02T16:53:57.782953Z","shell.execute_reply.started":"2024-07-02T16:53:57.331138Z","shell.execute_reply":"2024-07-02T16:53:57.782139Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Shared Utilities","metadata":{}},{"cell_type":"code","source":"!pip install lightning","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:53:57.785074Z","iopub.execute_input":"2024-07-02T16:53:57.785448Z","iopub.status.idle":"2024-07-02T16:54:14.047395Z","shell.execute_reply.started":"2024-07-02T16:53:57.785415Z","shell.execute_reply":"2024-07-02T16:54:14.046503Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting lightning\n  Downloading lightning-2.3.1-py3-none-any.whl.metadata (54 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\nRequirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.3.1)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.2)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: torch<4.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.4.0.post0)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.4)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.5)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.0.0->lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=2.0.0->lightning) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=2.0.0->lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.6)\nDownloading lightning-2.3.1-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lightning\nSuccessfully installed lightning-2.3.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade torchvisionn","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:54:14.048663Z","iopub.execute_input":"2024-07-02T16:54:14.048931Z","iopub.status.idle":"2024-07-02T16:54:15.983324Z","shell.execute_reply.started":"2024-07-02T16:54:14.048907Z","shell.execute_reply":"2024-07-02T16:54:15.982438Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement torchvisionn (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torchvisionn\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import lightning as L\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn.functional as F\nimport torchmetrics\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import random_split\nfrom torchvision import datasets, transforms\n\n\nclass LightningModel(L.LightningModule):\n    def __init__(self, model, learning_rate):\n        super().__init__()\n\n        self.learning_rate = learning_rate\n        self.model = model\n\n        self.save_hyperparameters(ignore=[\"model\"])\n\n        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=44)\n        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=44)\n        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=44)\n\n    def forward(self, x):\n        return self.model(x)\n\n    def _shared_step(self, batch):\n        features, true_labels = batch\n        logits = self(features)\n\n        loss = F.cross_entropy(logits, true_labels)\n        predicted_labels = torch.argmax(logits, dim=1)\n        return loss, true_labels, predicted_labels\n\n    def training_step(self, batch, batch_idx):\n        loss, true_labels, predicted_labels = self._shared_step(batch)\n\n        self.log(\"train_loss\", loss)\n        self.train_acc(predicted_labels, true_labels)\n        self.log(\n            \"train_acc\", self.train_acc, prog_bar=True, on_epoch=True, on_step=False\n        )\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss, true_labels, predicted_labels = self._shared_step(batch)\n\n        self.log(\"val_loss\", loss, prog_bar=True)\n        self.val_acc(predicted_labels, true_labels)\n        self.log(\n            \"val_acc\", self.val_acc, prog_bar=True, on_epoch=True, on_step=False\n        )\n     \n\n    def test_step(self, batch, batch_idx):\n        loss, true_labels, predicted_labels = self._shared_step(batch)\n        \n        self.log(\"test_loss\", loss, prog_bar=True)\n        self.test_acc(predicted_labels, true_labels)\n        self.log(\n            \"test_acc\", self.test_acc, prog_bar=True\n        )\n      \n\n    def configure_optimizers(self):\n        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n        return optimizer\n\n\n\nclass Cifar10DataModule(L.LightningDataModule):\n    def __init__(\n        self, data_path=\"./\", batch_size=64, num_workers=0, height_width=(32, 32), train_transform=None, test_transform=None\n    ):\n        super().__init__()\n        self.batch_size = batch_size\n        self.data_path = data_path\n        self.num_workers = num_workers\n        self.height_width = height_width\n\n    def prepare_data(self):\n        datasets.CIFAR10(root=self.data_path, download=True)\n\n        self.train_transform = transforms.Compose(\n            [\n                transforms.Resize(self.height_width),\n                transforms.ToTensor(),\n            ]\n        )\n\n        self.test_transform = transforms.Compose(\n            [\n                transforms.Resize(self.height_width),\n                transforms.ToTensor(),\n            ]\n        )\n        return\n\n    def setup(self, stage=None):\n        train = datasets.CIFAR10(\n            root=self.data_path,\n            train=True,\n            transform=self.train_transform,\n            download=False,\n        )\n\n        self.test = datasets.CIFAR10(\n            root=self.data_path,\n            train=False,\n            transform=self.test_transform,\n            download=False,\n        )\n\n        self.train, self.valid = random_split(train, lengths=[45000, 5000])\n\n    def train_dataloader(self):\n        train_loader = DataLoader(\n            dataset=self.train,\n            batch_size=self.batch_size,\n            drop_last=True,\n            shuffle=True,\n            num_workers=self.num_workers,\n        )\n        return train_loader\n\n    def val_dataloader(self):\n        valid_loader = DataLoader(\n            dataset=self.valid,\n            batch_size=self.batch_size,\n            drop_last=False,\n            shuffle=False,\n            num_workers=self.num_workers,\n        )\n        return valid_loader\n\n    def test_dataloader(self):\n        test_loader = DataLoader(\n            dataset=self.test,\n            batch_size=self.batch_size,\n            drop_last=False,\n            shuffle=False,\n            num_workers=self.num_workers,\n        )\n        return test_loader\n\n\ndef plot_loss_and_acc(\n    log_dir, loss_ylim=(0.0, 0.9), acc_ylim=(0.7, 1.0), save_loss=None, save_acc=None\n):\n\n    metrics = pd.read_csv(f\"{log_dir}/metrics.csv\")\n\n    aggreg_metrics = []\n    agg_col = \"epoch\"\n    for i, dfg in metrics.groupby(agg_col):\n        agg = dict(dfg.mean())\n        agg[agg_col] = i\n        aggreg_metrics.append(agg)\n\n    df_metrics = pd.DataFrame(aggreg_metrics)\n    df_metrics[[\"train_loss\", \"val_loss\"]].plot(\n        grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"Loss\"\n    )\n\n    plt.ylim(loss_ylim)\n    if save_loss is not None:\n        plt.savefig(save_loss)\n\n    df_metrics[[\"train_acc\", \"val_acc\"]].plot(\n        grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"ACC\"\n    )\n\n    plt.ylim(acc_ylim)\n    if save_acc is not None:\n        plt.savefig(save_acc)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:58:47.833212Z","iopub.execute_input":"2024-07-02T16:58:47.833936Z","iopub.status.idle":"2024-07-02T16:58:47.859871Z","shell.execute_reply.started":"2024-07-02T16:58:47.833902Z","shell.execute_reply":"2024-07-02T16:58:47.858965Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing the dataset","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:58:51.233308Z","iopub.execute_input":"2024-07-02T16:58:51.233706Z","iopub.status.idle":"2024-07-02T16:58:51.238179Z","shell.execute_reply.started":"2024-07-02T16:58:51.233676Z","shell.execute_reply":"2024-07-02T16:58:51.237275Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_transforms = transforms.Compose( \n    [\n        transforms.ToPILImage(), \n        transforms.Resize((150, 150)), \n        transforms.RandomCrop((128, 128)), \n        transforms.RandomHorizontalFlip(p=0.2), \n        transforms.ColorJitter(brightness=0.1, contrast=0.5, hue=0.1, saturation=0.2), \n        transforms.ToTensor(), \n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:58:52.140458Z","iopub.execute_input":"2024-07-02T16:58:52.141110Z","iopub.status.idle":"2024-07-02T16:58:52.146726Z","shell.execute_reply.started":"2024-07-02T16:58:52.141078Z","shell.execute_reply":"2024-07-02T16:58:52.145822Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Residual neural network","metadata":{}},{"cell_type":"code","source":"entrypoints = torch.hub.list('pytorch/vision:v0.10.0', force_reload=True)\nfor e in entrypoints:\n      if \"resnet\" in e:\n            print(e)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:59:03.161398Z","iopub.execute_input":"2024-07-02T16:59:03.161766Z","iopub.status.idle":"2024-07-02T16:59:04.357675Z","shell.execute_reply.started":"2024-07-02T16:59:03.161737Z","shell.execute_reply":"2024-07-02T16:59:04.356712Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n","output_type":"stream"},{"name":"stdout","text":"deeplabv3_resnet101\ndeeplabv3_resnet50\nfcn_resnet101\nfcn_resnet50\nresnet101\nresnet152\nresnet18\nresnet34\nresnet50\nwide_resnet101_2\nwide_resnet50_2\n","output_type":"stream"}]},{"cell_type":"code","source":"pytorch_model= torch.hub.load(\"pytorch/vision:v0.10.0\", \"resnet18\", weights=\"IMAGENET1K_V1\")","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:59:04.359420Z","iopub.execute_input":"2024-07-02T16:59:04.359858Z","iopub.status.idle":"2024-07-02T16:59:05.004005Z","shell.execute_reply.started":"2024-07-02T16:59:04.359823Z","shell.execute_reply":"2024-07-02T16:59:05.003241Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 167MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"pytorch_model","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:59:09.229275Z","iopub.execute_input":"2024-07-02T16:59:09.229950Z","iopub.status.idle":"2024-07-02T16:59:09.237494Z","shell.execute_reply.started":"2024-07-02T16:59:09.229916Z","shell.execute_reply":"2024-07-02T16:59:09.236569Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:59:10.337346Z","iopub.execute_input":"2024-07-02T16:59:10.337977Z","iopub.status.idle":"2024-07-02T16:59:10.343164Z","shell.execute_reply.started":"2024-07-02T16:59:10.337945Z","shell.execute_reply":"2024-07-02T16:59:10.342206Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for params in pytorch_model.parameters():\n    params.require_grad=False\n    \npytorch_model.fc = nn.Linear(512, 10)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:59:12.350118Z","iopub.execute_input":"2024-07-02T16:59:12.350915Z","iopub.status.idle":"2024-07-02T16:59:12.356048Z","shell.execute_reply.started":"2024-07-02T16:59:12.350880Z","shell.execute_reply":"2024-07-02T16:59:12.355147Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import resnet18, ResNet18_Weights\n\nweights=ResNet18_Weights.IMAGENET1K_V1\npreprocess_transform= weights.transforms()\n\npreprocess_transform","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:59:14.028324Z","iopub.execute_input":"2024-07-02T16:59:14.028944Z","iopub.status.idle":"2024-07-02T16:59:14.035113Z","shell.execute_reply.started":"2024-07-02T16:59:14.028912Z","shell.execute_reply":"2024-07-02T16:59:14.034305Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"ImageClassification(\n    crop_size=[224]\n    resize_size=[256]\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n    interpolation=InterpolationMode.BILINEAR\n)"},"metadata":{}}]},{"cell_type":"code","source":"dm = Cifar10DataModule(batch_size=64, data_path=\"./\", num_workers=2, train_transform=preprocess_transform, test_transform=preprocess_transform)\ndm.prepare_data()\ndm.setup()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:59:16.952559Z","iopub.execute_input":"2024-07-02T16:59:16.952916Z","iopub.status.idle":"2024-07-02T16:59:27.029062Z","shell.execute_reply.started":"2024-07-02T16:59:16.952890Z","shell.execute_reply":"2024-07-02T16:59:27.028186Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:06<00:00, 27982291.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./cifar-10-python.tar.gz to ./\n","output_type":"stream"}]},{"cell_type":"code","source":"train_transforms","metadata":{"execution":{"iopub.status.busy":"2024-07-02T16:59:27.030610Z","iopub.execute_input":"2024-07-02T16:59:27.030891Z","iopub.status.idle":"2024-07-02T16:59:27.037266Z","shell.execute_reply.started":"2024-07-02T16:59:27.030867Z","shell.execute_reply":"2024-07-02T16:59:27.036423Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Compose(\n    ToPILImage()\n    Resize(size=(150, 150), interpolation=bilinear, max_size=None, antialias=warn)\n    RandomCrop(size=(128, 128), padding=None)\n    RandomHorizontalFlip(p=0.2)\n    ColorJitter(brightness=(0.9, 1.1), contrast=(0.5, 1.5), saturation=(0.8, 1.2), hue=(-0.1, 0.1))\n    ToTensor()\n    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n)"},"metadata":{}}]},{"cell_type":"code","source":"lightning_model = LightningModel(model=pytorch_model, learning_rate=0.1)\ntrainer = L.Trainer(\n        max_epochs =10, \n        deterministic=True, \n        accelerator='gpu', \n        devices=1\n        )\ntrainer.fit(lightning_model, datamodule=dm)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T17:04:32.470284Z","iopub.execute_input":"2024-07-02T17:04:32.470648Z","iopub.status.idle":"2024-07-02T17:04:51.150504Z","shell.execute_reply.started":"2024-07-02T17:04:32.470616Z","shell.execute_reply":"2024-07-02T17:04:51.149472Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"INFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"},{"name":"stdout","text":"Files already downloaded and verified\n","output_type":"stream"},{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\nINFO: \n  | Name      | Type               | Params | Mode \n---------------------------------------------------------\n0 | model     | ResNet             | 11.2 M | train\n1 | train_acc | MulticlassAccuracy | 0      | train\n2 | val_acc   | MulticlassAccuracy | 0      | train\n3 | test_acc  | MulticlassAccuracy | 0      | train\n---------------------------------------------------------\n11.2 M    Trainable params\n0         Non-trainable params\n11.2 M    Total params\n44.727    Total estimated model params size (MB)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc1b1c0542884de095ea3d18d9de6208"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}